{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nagamharitha/A-real-time-chat-room/blob/main/Week6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0cSb7Cts2u-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b67beca4-d8ac-44e0-8dbc-c7b1a24d4e08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHCwZ0WitHHg"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHJWfemGtIgo"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
        "from pyspark.ml.classification import DecisionTreeClassifier, LogisticRegression\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "# Initialize Spark session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Logistic Regression\") \\\n",
        "    .getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CbstGvlwtMlq"
      },
      "outputs": [],
      "source": [
        "pandas_df = pd.read_excel('/content/drive/MyDrive/ML CN7030 /bank (1).xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dff = spark.createDataFrame(pandas_df)"
      ],
      "metadata": {
        "id": "Q25rEaNYnx-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zeCA9ur8tQCQ"
      },
      "outputs": [],
      "source": [
        "print(dff.count())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9vZMBIytQhe"
      },
      "outputs": [],
      "source": [
        "dff.select(\"deposit\").distinct().show()\n",
        "dff.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIFyMXRYubDF"
      },
      "outputs": [],
      "source": [
        "print(\"yes\",dff.select(\"deposit\").where(\"deposit=='yes'\").count())\n",
        "print(\"No\",dff.select(\"deposit\").where(\"deposit=='no'\").count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TSx2cplkueW8"
      },
      "outputs": [],
      "source": [
        "# checking the distinct values in string columns of the dataframe using functional programming\n",
        "[print(\"column name\",dff[t[0]].name,dff.select(t[0]).distinct().show()) for t in dff.dtypes if t[1]=='string' ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRBpw_ofuli_"
      },
      "source": [
        "Display Integer colums\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0iDTwYy-ugSl"
      },
      "outputs": [],
      "source": [
        "# taking only integer features\n",
        "numeric_features = [t[0] for t in dff.dtypes if t[1] == 'int']\n",
        "dff.select(numeric_features).describe().toPandas().transpose()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ec_AVFxluo48"
      },
      "outputs": [],
      "source": [
        "#find out is there any null value in any column\n",
        "print(\"total records:\",dff.count())\n",
        "[print(col,\"Total null values\",dff.where(dff[col].isNull()).count()) for col in dff.columns]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcHId1ZHuxGJ"
      },
      "source": [
        "Selecting the features of feature vectors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJghEy14uuhF"
      },
      "outputs": [],
      "source": [
        "# Non Numeric features\n",
        "df = dff.select('job', 'marital', 'education', 'default',  'housing', 'loan', 'contact', 'duration',  'poutcome', 'deposit')\n",
        "cols = df.columns\n",
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JdAI5qQ3u2E3"
      },
      "outputs": [],
      "source": [
        "df = dff.select('age', 'job', 'marital', 'education', 'default', 'balance', 'housing', 'loan', 'contact', 'duration', 'campaign', 'pdays', 'previous', 'poutcome', 'deposit')\n",
        "cols = df.columns\n",
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9inxDlmGu4j2"
      },
      "outputs": [],
      "source": [
        "# Now we will apply string indexing to categorial variables using pipe line\n",
        "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
        "categoricalColumns = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'poutcome']\n",
        "stages = []\n",
        "for categoricalCol in categoricalColumns:\n",
        "    stringIndexer = StringIndexer(inputCol = categoricalCol, outputCol = categoricalCol + 'Index')\n",
        "    encoder = OneHotEncoder(inputCols=[stringIndexer.getOutputCol()], outputCols=[categoricalCol + \"classVec\"])\n",
        "    print(stringIndexer.getOutputCol())\n",
        "    stages += [stringIndexer, encoder]\n",
        "label_stringIdx = StringIndexer(inputCol = 'deposit', outputCol = 'label')\n",
        "print(label_stringIdx)\n",
        "stages += [label_stringIdx]\n",
        "numericCols = ['age','balance', 'duration', 'campaign', 'pdays', 'previous']\n",
        "assemblerInputs = [c + \"classVec\" for c in categoricalColumns] + numericCols\n",
        "print(assemblerInputs)\n",
        "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
        "stages += [assembler]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdjmLbfpu9Fu"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml import Pipeline\n",
        "pipeline = Pipeline(stages = stages)\n",
        "pipelineModel = pipeline.fit(df)\n",
        "df = pipelineModel.transform(df)\n",
        "df.show(12,True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "deEPHLvUu-4D"
      },
      "outputs": [],
      "source": [
        "print(df.select(\"features\").show(1))\n",
        "print(cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbAVxyrtvCQF"
      },
      "outputs": [],
      "source": [
        "# feature vector is in features  from assembler.\n",
        "selectedCols = ['label', 'features'] + cols\n",
        "dfSelected = df.select(selectedCols)\n",
        "dfSelected.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOEFzWDyvC2c"
      },
      "outputs": [],
      "source": [
        "# this is code for multiple classification using logistic Regression\n",
        "from pyspark.ml.classification import OneVsRest\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "train, test = dfSelected.randomSplit([0.7, 0.3], seed = 2018)\n",
        "lr = LogisticRegression(maxIter=100, \\\n",
        "\n",
        "                        featuresCol=\"features\", \\\n",
        "\n",
        "                        labelCol='label')\n",
        "ovr = OneVsRest(classifier=lr, \\\n",
        "                labelCol='label', \\\n",
        "                featuresCol='features')\n",
        "\n",
        "ovrModel = ovr.fit(train)\n",
        "predictionsovr = ovrModel.transform(test)\n",
        "predictionsovr.show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MhTRivzvGNK"
      },
      "outputs": [],
      "source": [
        "from pyspark.mllib.evaluation import MulticlassMetrics\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# Create MulticlassMetrics object\n",
        " #Convert predictions and labels to RDD for MulticlassMetrics\n",
        "prediction_and_labels = predictionsovr.select(\"prediction\", \"label\") \\\n",
        "    .withColumnRenamed(\"indexedLabel\", \"label\") \\\n",
        "    .toPandas()  # Convert to Pandas DataFrame for easier manipulation\n",
        "# Create a confusion matrix using Pandas\n",
        "confusion_matrix = pd.crosstab(prediction_and_labels['label'], prediction_and_labels['prediction'], rownames=['Actual'], colnames=['Predicted'])\n",
        "\n",
        "# Plot the confusion matrix using Seaborn and Matplotlib\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(\\\n",
        "labelCol=\"label\", predictionCol=\"prediction\",\\\n",
        "metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictionsovr)\n",
        "print(\"Test accuracy =  \" , accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0rVFHqCvJFF"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "train, test = dfSelected.randomSplit([0.7, 0.3], seed = 2018)\n",
        "print(\"Training Dataset Count: \" + str(train.count()))\n",
        "print(\"Test Dataset Count: \" + str(test.count()))\n",
        "dt = DecisionTreeClassifier(featuresCol = 'features', labelCol = 'label', maxDepth = 3)\n",
        "dtModel = dt.fit(train)\n",
        "predictions = dtModel.transform(test)\n",
        "\n",
        "#predictions.select(\"label\",\"prediction\").show(10)\n",
        "predictions.select('age', 'job', 'label', 'rawPrediction', 'prediction', 'probability').show(10)\n",
        "print(\"Total Actual Positive\",predictions.select(\"label\").where('label == 1.0').count())\n",
        "print(\"Total Actual Negative\",predictions.select(\"label\").where('label == 0.0').count())\n",
        "pr = predictions.toPandas()\n",
        "TruePositive =0\n",
        "FalsePositive=0\n",
        "TrueNegative=0\n",
        "FalseNegative=0\n",
        "Postive=1.0\n",
        "Negative=0.0\n",
        "pos=0\n",
        "Neg=0\n",
        "\n",
        "print(\"Total\",len(pr[\"label\"]))\n",
        "for lbl in range(len(pr[\"label\"])):\n",
        "  if  pr[\"prediction\"][lbl]==Postive:\n",
        "    pos+=1\n",
        "    if pr[\"prediction\"][lbl]==pr[\"label\"][lbl]:\n",
        "      TruePositive+=1\n",
        "    else:\n",
        "      FalsePositive+=1\n",
        "  if  pr[\"prediction\"][lbl]==Negative:\n",
        "    Neg+=1\n",
        "    if pr[\"prediction\"][lbl]==pr[\"label\"][lbl]:\n",
        "      TrueNegative+=1\n",
        "    else:\n",
        "      FalseNegative+=1\n",
        "print(\"Total Positive & Negative in Prediction. Pos: \",pos,\",Neg\",Neg)\n",
        "print(\"TruePostive\",TruePositive,\"FalsePostive\",FalsePositive)\n",
        "print(\"TrueNegative\",TrueNegative,\"FalseNegative\",FalseNegative)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sH4VyqLovNTG"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "evaluator = BinaryClassificationEvaluator()\n",
        "\n",
        "print(\"Test Area Under ROC: \" + str(evaluator.evaluate(predictions, {evaluator.metricName: \"areaUnderROC\"})))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EndpOww9vQVP"
      },
      "outputs": [],
      "source": [
        "#RandomForest\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "#rf = RandomForestClassifier(featuresCol = 'features', labelCol = 'label')\n",
        "rf = RandomForestClassifier(featuresCol='features', labelCol='label', maxDepth = 4,numTrees=20)\n",
        "train, test = dfSelected.randomSplit([0.7, 0.3], seed = 2018)\n",
        "rfModel = rf.fit(train)\n",
        "predictions = rfModel.transform(test)\n",
        "pr = predictions.toPandas()\n",
        "print(\"Total Actual Positive\",predictions.select(\"label\").where('label == 1.0').count())\n",
        "print(\"Total Actual Negative\",predictions.select(\"label\").where('label == 0.0').count())\n",
        "\n",
        "evaluator = BinaryClassificationEvaluator()\n",
        "print(\"Test Area Under ROC: \" + str(evaluator.evaluate(predictions, {evaluator.metricName: \"areaUnderROC\"})))\n",
        "TruePositive =0\n",
        "FalsePositive=0\n",
        "TrueNegative=0\n",
        "FalseNegative=0\n",
        "Postive=1.0\n",
        "Negative=0.0\n",
        "pos=0\n",
        "Neg=0\n",
        "print(\"Total\",len(pr[\"label\"]))\n",
        "for lbl in range(len(pr[\"label\"])):\n",
        "  if  pr[\"prediction\"][lbl]==Postive:\n",
        "    pos+=1\n",
        "    if pr[\"prediction\"][lbl]==pr[\"label\"][lbl]:\n",
        "      TruePositive+=1\n",
        "    else:\n",
        "      FalsePositive+=1\n",
        "  if  pr[\"prediction\"][lbl]==Negative:\n",
        "    Neg+=1\n",
        "    if pr[\"prediction\"][lbl]==pr[\"label\"][lbl]:\n",
        "      TrueNegative+=1\n",
        "    else:\n",
        "      FalseNegative+=1\n",
        "print(\"Total positive & Negative in Predictions, Pos\",pos,\"Neg\",Neg)\n",
        "print(\"TruePostive\",TruePositive,\"FalsePostive\",FalsePositive)\n",
        "print(\"TrueNegative\",TrueNegative,\"FalseNegative\",FalseNegative)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vCRkg0DvTQt"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, GBTClassifier\n",
        "\n",
        "ml = GBTClassifier(maxIter=10, featuresCol='features', labelCol='label',maxDepth = 10)\n",
        "train, test = dfSelected.randomSplit([0.7, 0.2], seed = 2018)\n",
        "mlModel = ml.fit(train)\n",
        "predictions = mlModel.transform(test)\n",
        "\n",
        "evaluator = BinaryClassificationEvaluator()\n",
        "print(\"Test Area Under ROC: \" + str(evaluator.evaluate(predictions, {evaluator.metricName: \"areaUnderROC\"})))\n",
        "\n",
        "# Calculate accuracy and F-1 score\n",
        "#accuracy_evaluator = MulticlassClassificationEvaluator(metricName='accuracy')\n",
        "#accuracy = accuracy_evaluator.evaluate(predictions.select('label', 'prediction'))\n",
        "\n",
        "#f1_score_evaluator = MulticlassClassificationEvaluator(metricName='f1')\n",
        "#f1_score = f1_score_evaluator.evaluate(predictions.select('label', 'prediction'))\n",
        "#print(accuracy, f1_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUlzdtAFvuFY",
        "outputId": "90c77e99-a454-48f5-c3a5-ffb93762465e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8999779711421949"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
        "gbt = GBTClassifier(maxIter=10)\n",
        "paramGrid = (ParamGridBuilder()\n",
        "             .addGrid(gbt.maxDepth, [2, 4, 6])\n",
        "             .addGrid(gbt.maxBins, [20, 60])\n",
        "             .addGrid(gbt.maxIter, [10, 20])\n",
        "             .build())\n",
        "cv = CrossValidator(estimator=gbt, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n",
        "# Run cross validations.  This can take about 6 minutes since it is training over 20 trees!\n",
        "cvModel = cv.fit(train)\n",
        "predictions = cvModel.transform(test)\n",
        "evaluator.evaluate(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGu7M7Cwvv2T",
        "outputId": "5cb08aa0-2633-4b07-afb9-279f26db70af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----------+\n",
            "|label|prediction|\n",
            "+-----+----------+\n",
            "|  1.0|       1.0|\n",
            "|  1.0|       0.0|\n",
            "|  1.0|       1.0|\n",
            "|  1.0|       0.0|\n",
            "|  1.0|       1.0|\n",
            "|  1.0|       1.0|\n",
            "|  1.0|       1.0|\n",
            "|  1.0|       0.0|\n",
            "|  1.0|       1.0|\n",
            "|  1.0|       1.0|\n",
            "|  1.0|       1.0|\n",
            "|  1.0|       0.0|\n",
            "|  1.0|       1.0|\n",
            "+-----+----------+\n",
            "only showing top 13 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "predictions.select('label', 'prediction').show(13)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMV92VPgvxgU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a81b3c1d-aca9-4d4a-c05b-8d36d3ba9f77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.classification import GBTClassifier, OneVsRest\n",
        "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "path=\"/content/drive/MyDrive/ML CN7030 /Week5/bezdekIris.data\"\n",
        "# Start Spark session\n",
        "spark = SparkSession.builder.appName(\"GBTClassifier-Multiclass\").getOrCreate()\n",
        "\n",
        "# Load dataset (replace with your path)\n",
        "# Assuming the order of columns is sepal_length, sepal_width, petal_length, petal_width, species\n",
        "iris = spark.read.csv(path, header=False, inferSchema=True).toDF(\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"species\")\n",
        "# Prepare features\n",
        "feature_cols = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
        "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
        "iris = assembler.transform(iris)\n",
        "\n",
        "# Index labels\n",
        "indexer = StringIndexer(inputCol=\"species\", outputCol=\"label\")\n",
        "iris = indexer.fit(iris).transform(iris)\n",
        "\n",
        "# Train-test split\n",
        "train, test = iris.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# Initialize GBTClassifier\n",
        "gbt = GBTClassifier(maxIter=20, maxDepth=3, stepSize=0.1)\n",
        "\n",
        "# Wrap in OneVsRest for multiclass\n",
        "ovr = OneVsRest(classifier=gbt)\n",
        "\n",
        "# Train\n",
        "model = ovr.fit(train)\n",
        "\n",
        "# Predict\n",
        "predictions = model.transform(test)\n",
        "\n",
        "# Evaluate\n",
        "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "spark.stop()"
      ],
      "metadata": {
        "id": "fEzcKePOKqL6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26389bea-7990-4c4d-bb36-91dc4ef45452"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.9583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08f666eb",
        "outputId": "7e972df7-cd1d-439f-a923-83f5be4d8595"
      },
      "source": [
        "iris.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- 5.1: double (nullable = true)\n",
            " |-- 3.5: double (nullable = true)\n",
            " |-- 1.4: double (nullable = true)\n",
            " |-- 0.2: double (nullable = true)\n",
            " |-- Iris-setosa: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}